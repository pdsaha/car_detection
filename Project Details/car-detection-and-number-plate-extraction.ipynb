{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport pytesseract\nimport pandas as pd\nimport os\nfrom datetime import datetime\nfrom ultralytics import YOLO\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.models import Model\nimport numpy as np\nimport tensorflow as tf\n\n# Paths\nINPUT_FOLDER = '/kaggle/input/car-number-plate-images/'  # Adjust for your dataset\nOUTPUT_CSV = '/kaggle/working/plate_results.csv'\n\n# Setup pytesseract\npytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n\n# Load YOLOv5\nyolo_model = YOLO(\"yolov5s.pt\")  # Replace with your license plate-trained model\n\n# Load InceptionResNetV2 and VGG16\ninception_model = tf.keras.applications.InceptionResNetV2(weights='imagenet', include_top=False, pooling='avg')\nvgg_model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n\n# Function for OCR\n\ndef perform_ocr(plate_img):\n    gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n    text = pytesseract.image_to_string(thresh, config='--psm 7')\n    return ''.join(filter(str.isalnum, text))\n\n# Function to get features from CNN\n\ndef extract_features(model, image):\n    resized = cv2.resize(image, (224, 224))\n    img_array = img_to_array(resized)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n    features = model.predict(img_array)\n    return features.flatten()\n\n# Process each image\nresults = []\n\nfor filename in os.listdir(INPUT_FOLDER):\n    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n        img_path = os.path.join(INPUT_FOLDER, filename)\n        image = cv2.imread(img_path)\n\n        # --- 1. YOLOv5 Detection ---\n        yolo_detections = yolo_model.predict(source=image, conf=0.5, save=False)\n\n        for det in yolo_detections:\n            for box in det.boxes.data:\n                x1, y1, x2, y2, score, class_id = box.tolist()\n                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n                plate_img = image[y1:y2, x1:x2]\n                plate_text = perform_ocr(plate_img)\n\n                # --- 2. InceptionResNetV2 Features ---\n                inc_features = extract_features(inception_model, plate_img)\n\n                # --- 3. VGG16 Features ---\n                vgg_features = extract_features(vgg_model, plate_img)\n\n                results.append({\n                    \"filename\": filename,\n                    \"plate_text\": plate_text,\n                    \"timestamp\": datetime.now().isoformat(),\n                    \"bbox\": f\"{x1},{y1},{x2},{y2}\",\n                    \"model\": \"YOLOv5 + OCR\",\n                    \"inception_feature_0\": inc_features[0],  # Just storing first few features for sample\n                    \"vgg_feature_0\": vgg_features[0]\n                })\n\n# Save results\nresults_df = pd.DataFrame(results)\nresults_df.to_csv(OUTPUT_CSV, index=False)\nprint(\"Detection and OCR complete. Results saved to:\", OUTPUT_CSV)\nresults_df.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}